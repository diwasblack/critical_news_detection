\chapter{Experiments and Results}
\label{ch:results}

We implemented the program in Python 2.7 using Kivy for the user interface. 
% cite cockatoo
We used the cockatoo library written in Python for calculating the distance between two cocktails.
The input  screen file is an MS Excel file in a specific format with pre-specified headers, sheet names, and data types. The output file of the program is also an MS Excel file with a list of new candidate cocktails. The candidate cocktails are sorted in descending order by their ranks.

We used 2 different input files with different proteins to compare the performance of this algorithm with previous algorithms (AED\cite{OptimizeAED} and GenScreen\cite{SamyamThesis}). The proteins used in these experiments are AbIPPase and KpIPPase. Each input file for a protein is the combination of results of 4 separate screening experiments on 96-well plates. Moreover, for each input file, we experimented with a different set of parameters - number of iterations, population size, tournament size, and mutation rate.

To evaluate our algorithm, we compared the wet lab experiment results of our algorithm with the results of AED and GenScreen for the two proteins mentioned above. We observed the number of hits for our algorithm. Our goal is to get some novel hits in that were not detected by GenScreen.

\section{Tuning the Parameters of Genetic Algorithm} \label{sec:results-tuning}

There are 4 important parameters of genetic algorithm that need to be properly tuned:
  \begin{enumerate}
  \item Number of iterations
  \item Population size 
  \item Tournament size 
  \item Mutation rate 
  \end{enumerate}

We compare these parameters with \textit{score} and \textit{number of distinct families}. Here, the score of a cocktail is its rank score. A cocktail is considered distinct if the combination of its chemicals (i.e, pH, the name of precipitant, and the name of salt) are different from other cocktails. In the wet lab, concentrations of precipitant and salt are varied in a family.

\subsection{Number of Iterations} \label{sec:results-iterations}

In most genetic algorithm applications, high number of iterations are likely to lead to an optimal solution. We can see that the mean score increases as the number of iterations increases in \figureref{fig:ivs}. 

\begin{figure}[H]
	\cfig{2}{ivs.png}{5}
	\caption{Number of Iterations vs. Score}
	\label{fig:ivs}
\end{figure}

Initially, the number of distinct families is high because it represents the whole initial population itself as seen in \figureref{fig:ivd}. Then, gradually after certain iterations, the number of distinct families goes down. This might be due to the algorithm favoring high ranking conditions over lower ones.

\begin{figure}[H]
	\cfig{2}{ivd.png}{5}
	\caption{Number of Iterations vs. Distinct families}
	\label{fig:ivd}
\end{figure}

\subsection{Population Size} \label{sec:results-population}

There is no relation between population size and score as seen in \figureref{fig:pvs}. This might be because higher ranking conditions are found early on and are always propagated to the next generation no matter what population size is selected.

\begin{figure}[H]
	\cfig{2}{pvs.png}{5}
	\caption{Population size vs. Score}
	\label{fig:pvs}
\end{figure}

There is a positive correlation between the population size and the number of distinct families as seen in \figureref{fig:pvd}. Larger population size implies that the algorithm can cover conditions from larger chemical space. This adds variety in the generated conditions.

\begin{figure}[H]
	\cfig{2}{pvd.png}{5}
	\caption{Population size vs. Distinct families}
	\label{fig:pvd}
\end{figure}

\subsection{Tournament Size} \label{sec:results-tournament}
There is no relation between tournament size (for up to 5) and score as seen in \figureref{fig:tvs} in our experiments.
We found that the number of distinct families decreases with increase in tournament size as shown in \figureref{fig:tvd}. Increasing tournament size may lead choosing the same fit parents again. Hence, the tournament size should be kept low.


\begin{figure}[H]
	\cfig{2}{tvs.png}{5}
	\caption{Tournament size vs. Score}
	\label{fig:tvs}
\end{figure}

\begin{figure}[H]
	\cfig{2}{tvd.png}{5}
	\caption{Tournament size vs. Distinct families}
	\label{fig:tvd}
\end{figure}

\subsection{Mutation Rate} \label{sec:results-mutation}

\figureref{fig:mvs} shows that there is no relation between mutation rate and mean score in our experiments. Setting mutation rate to 0 yields less variety (distinct families) in output because there is no variation in genes. The relationship between mutation rate and the number of distinct families can  be seen in \figureref{fig:mvd}. Mutation rate of 0.3 is recommended for experiments.

\begin{figure}[H]
	\cfig{2}{mvs.png}{5}
	\caption{Mutation rate vs. Score}
	\label{fig:mvs}
\end{figure}

\begin{figure}[H]
	\cfig{2}{mvd.png}{5}
	\caption{Mutation rate vs. Distinct families}
	\label{fig:mvd}
\end{figure}


\section{Runtime Analysis} \label{sec:results-runtime}

The runtime of the algorithm largely depends upon the total number of calculations made while computing the feature vectors of chemicals and cocktails. We used a HP Spectre notebook with 8 GB of RAM, Intel(R) Core(TM) i7-6500 CPU @ 2.5 GHz CPU with Windows 10 Home 64-bit operating system for measuring runtime of the algorithm for all kinds of different scenarios. The protein used in these evaluations is AbIPP.

\subsection{Timing Before and After Optimizations}

%\subsection{Runtime before any Optimization} \label{sec:results-runtime-before}

This section shows the runtime of the algorithm before any attempt was made to reduce the overhead in calculating the distance between cocktails.

Before any optimizations, the time complexity was $O ( g * p^2 * i^2 )$ where $g$ is the gene length, $p$ is the population size, and $i$ is the total number of iterations. 
When the algorithm was run with $population\_size$ of $100$ for $5$ $iterations$, the total runtime was \textbf{3 minutes and 32 seconds}. This runtime accounts for the time taken while loading and preprocessing data as well.


%\subsection{Runtime After Optimization of Reappearing Chemicals} \label{sec:results-runtime-chemical}

Next we tried to determine how much we could save if feature vectors of chemicals are stored in a dictionary. 
We stored the feature vector of each chemical in our database to speed up the algorithm. The time complexity after this optimization is $O ( p^2 * i^2 )$. We found out that by doing so the running time got reduced to just \textbf{1 minute and 51 seconds} when the algorithm was run with $population\_size$ of $100$ for $5$ $iterations$.

%\subsection{Runtime After Optimization of Overlapping Cocktails} \label{sec:results-runtime-after}

Next we analyzed the benefit of determining overlapping cocktails over generations.
%After optimizing for reappearing chemicals, we observed that there was a high percentage of overlap between cocktails of previous and later generations. 
%This led us to optimize the algorithm even further. 
The time complexity after this optimization is $O ( p^2 * i^2 )$. We found out that by doing so the running time got reduced to just \textbf{10 seconds} when the algorithm was run with $population\_size$ of $100$ for $5$ $iterations$.

\subsection{Comparison of Runtime with GenScreen and AED} \label{sec:results-runtime-summary}

The comparison of runtime of our algorithm with AED and GenScreen is shown in \tableref{runtime_comparision_table}. For our algorithm and GenScreen, the $population\_size$ is $100$ and is run for $5$ $iterations$. Despite searching larger chemical space, novelty search performs close to GenScreen and AED in terms of runtime.

\begin{table}[htbp]
\begin{center}
\caption{Comparision of average execution time with GenScreen and AED}
\begin{tabular}{|c|c|c|c|c|}
\hline
\textbf{Protein} & \textbf{Novelty Search} & \textbf{GenScreen} & \textbf{AED} \\
\hline
\textbf{AbIPPase} & 10.36 & 4.39 & 2.23  \\
\hline
\textbf{KpIPPase} & 10.78 & 3.85 & 1.12  \\
\hline
\end{tabular}
\label{runtime_comparision_table}
\end{center}
\end{table}

\section{Comparison with AED and GenScreen  over Previous Wet Lab Experiments} \label{sec:results-comparison}

We used AbIpp-Combined screen file to compare the output of our algorithm with the output of GenScreen. We found out that the top 10 mean score for both algorithms was 2.72 as shown in \tableref{scores_table}. The number of distinct families was higher for our algorithm than that for GenScreen. Moreover, in \tableref{scores_table}, we can see that the number of distinct precipitants and salts is higher for our algorithm as well. This is because our algorithm explores the unexplored territories of chemical search space, thereby creating more variety in the generated conditions.

%The running time of the algorithm is much slower than that of GenScreen. This is mainly due to the overhead in calculating the distances between cocktails. This can possibly be overcome by storing the fingerprint of every chemical, and retrieving them when necessary.
The running time of the algorithm is comparable to that of GenScreen after overcoming the overhead that lied in calculating the feature vectors of same chemicals over and over again. We solved the problem by storing the fingerprint of every chemical, and retrieving them when necessary.

\begin{table}[htbp]
\begin{center}
\caption{Comparison with GenScreen}
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
\textbf{} & \textbf{} & \textbf{Top 10} & \textbf{Distinct} & \textbf{No. of} & \textbf{No.} & \textbf{} \\
\textbf{Algorithm} & \textbf{Runtime} & \textbf{Mean} & \textbf{families} & \textbf{Precip-} & \textbf{of} & \textbf{Total} \\
\textbf{} & \textbf{} & \textbf{Score} & \textbf{} & \textbf{itants} & \textbf{Salts} & \textbf{} \\
\hline
GenScreen & 0:09 & 2.72 & 129 & 25 & 20 & 723 \\
\hline
Novelty & 0:15 & 2.72 & 167 & 35 & 42 & 811 \\
\hline
\end{tabular}
\label{scores_table}
\end{center}
\end{table}


As shown in \tableref{aed_table}, there were 94 overlapping conditions between GenScreen and our algorithm. Other than 755 conditions generated only by our algorithm, the total number of overlaps between AED and our algorithm was 60. Finally, there were 33 common conditions generated by all of the three algorithms.

\begin{table}[htbp]
\begin{center}
\caption{Comparison with GenScreen and AED for AbIPPase}
\begin{tabular}{|c|c|c|c|c|}
\hline
 & \textbf{GenScreen} & \textbf{AED} & \textbf{Novelty} & \textbf{All} \\
\hline
\textbf{GenScreen} & 622 & 153 & 94 & 33 \\
\hline
\textbf{AED} & 153 & 2093 & 60 & 33 \\
\hline
\textbf{Novelty} & 94 & 60 & 755 & 33 \\
\hline
\end{tabular}
\label{aed_table}
\end{center}
\end{table}

Crystalline conditions are those conditions that could form crystals in the wet lab. The goal of our algorithm is to get as many crystalline conditions as possible. \tableref{common_table} lists the overlapping crystalline conditions generated by AED, GenScreen, and our algorithm for protein AbIPPase. Our algorithm has 6 common crystalline conditions with associative experimental design(AED) and 9 common crystalline conditions with GenScreen.

\begin{table}[htbp]
\begin{center}
\caption{Comparision of common crystalline conditions for AbIPPase}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Algorithm} & \textbf{No. of} & \textbf{No. of crystalline} & \textbf{No. of common} \\
 & \textbf{conditions} & \textbf{conditions} & \textbf{crystalline conditions} \\
\hline
\textbf{GenScreen} & 96 & 49 & 9 \\
\hline
\textbf{AED} & 96 & 20 & 6 \\
\hline

\end{tabular}
\label{common_table}
\end{center}
\end{table}


\section{Wet-lab Experiments} \label{sec:results-wet-lab}
After comparing the output of our algorithm with GenScreen and AED, we evaluate our algorithm based on  wet lab experiments. Each experiment is set up using a 96-well plate, i.e., 96 conditions are selected from the output file of our algorithm. All 96 conditions produced crystals. For the same protein, GenScreen had 96 hits, and AED had 91 hits. \figureref{fig:crystal1}, \figureref{fig:crystal2}, and \figureref{fig:crystal3} list all of the crystalline conditions generated by our algorithm. There were 3 overlaps with AED and no overlap with GenScreen.  Therefore, there are 93 unique crystalline conditions generated only by our algorithm. Furthermore, the crystalline conditions generated by our algorithm utilized 7 distinct buffers, 13 distinct precipitants, and 13 distinct salts. This is slightly more than that utilized by AED which has 6 buffers, 12 precipitants, and 9 salts, and by GenScreen which has 6 buffers, 10 precipitants, and 11 salts. This diversity in the composition of crystalline conditions is because our algorithm explores unexplored areas of chemical search space.
\newpage

\begin{figure}[H]
	\cfig{2}{crystal1.PNG}{5}
	\caption{Crystalline conditions generated by Novelty Search for the protein ConA (Part I)}
	\label{fig:crystal1}
\end{figure}

\newpage
\begin{figure}[H]
	\cfig{2}{crystal2.PNG}{5}
	\caption{Crystalline conditions generated by Novelty Search for the protein ConA (Part II)}
	\label{fig:crystal2}
\end{figure}

\newpage
\begin{figure}[H]
	\cfig{2}{crystal3.PNG}{5}
	\caption{Crystalline conditions generated by Novelty Search for the protein ConA (Part III)}
	\label{fig:crystal3}
\end{figure}

\section{Summary} \label{rel:summary}

In this chapter, we explained how we applied the novelty search for getting a diverse set of individuals. We also described how different parameters like mutation rate, population size, and others effect the output of the algorithm. We then compared the result of our algorithm with that of AED and GenScreen.

% \section{Running Time for GenScreen} \label{sec:results-running}

% We have compared the running time of GenScreen and AED. We have used (provide your PC configuration) for time analysis. \tableref{tbl:exeTime} compares the average program execution time of GenScreen and AED for the 3 proteins tested. It can be observed that GenScreen produces within 2 seconds and with similar running times as AED. We may state that GenScreen produces good crystalline conditions without increasing the running time.

% \FloatBarrier
% \begin{table}[h]
% 	\centering
%     \setlength\extrarowheight{3pt}
%     \caption{Comparison of execution times of AED and GenScreen}
%     \label{tbl:exeTime}
%     \begin{tabular} {| m{2.5cm} | m{2.3cm} | m{2.3cm} |}
%     \hline
%     \multirow {2}{*}{ \textbf {Protein}} & \multicolumn {2}{c|}{\textbf {Average execution time (seconds)}} \\ \cline{2-3}
%     & \textbf {AED} & \textbf {GenScreen} \\ \hline
%     AbIPPase & 2.23 & 1.43 \\ \hline
%     CjIPPase & 1.48 & 1.94 \\ \hline
%     KpIPPase & 1.12 & 1.12 \\ \hline
    
    
% %     \textbf {Protein} & \centering \textbf {\# of conditions (GenScreen)} & \centering \textbf {\# of conditions (AED)} & \centering \textbf {Common conditions} & \centering \textbf {AED hits} & \centering \textbf {Common hits} &  \textbf { \centering \% of AED} \\
% %     \hline
% % 	AbIPPase & 896 & 812 & 258 & 20 & 6 & 30\% \\
% %      \hline
% %      CjIPPase & 1187 & 588 & 339 & 16 & 7 & 43.75\% \\
% %      \hline	
% %      KpIPPase & 894 & 383 & 154 & 19 & 5 & 26.3\% \\
% %      \hline
%     \end{tabular}
% \end{table}


